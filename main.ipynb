{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: openai in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (2.12.0)\n",
      "Requirement already satisfied: sniffio in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (5.1.1)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 5.1.1\n",
      "    Uninstalling sentence-transformers-5.1.1:\n",
      "      Successfully uninstalled sentence-transformers-5.1.1\n",
      "Successfully installed sentence-transformers-5.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.2.1-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from chromadb) (2.12.0)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp313-cp313-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from chromadb) (2.3.3)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from chromadb) (4.15.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.23.2-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from chromadb) (0.22.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from chromadb) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from chromadb) (6.0.3)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.11.4-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from chromadb) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2025.10.5)\n",
      "Requirement already satisfied: packaging>=19.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: anyio in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.41.1-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: sympy in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.71.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.35.3)\n",
      "Requirement already satisfied: filelock in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.9.0)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.7.1-cp313-cp313-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.1-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Downloading chromadb-1.2.1-cp39-abi3-win_amd64.whl (20.7 MB)\n",
      "   ---------------------------------------- 0.0/20.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 6.6/20.7 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 11.3/20.7 MB 26.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 15.7/20.7 MB 24.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  20.4/20.7 MB 23.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 20.7/20.7 MB 21.8 MB/s  0:00:00\n",
      "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl (150 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 4.5/4.7 MB 20.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 15.4 MB/s  0:00:00\n",
      "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 14.0 MB/s  0:00:00\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.41.1-py2.py3-none-any.whl (221 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading mmh3-5.2.0-cp313-cp313-win_amd64.whl (41 kB)\n",
      "Downloading onnxruntime-1.23.2-cp313-cp313-win_amd64.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 3.1/13.5 MB 15.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.2/13.5 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.6/13.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.1/13.5 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 13.6 MB/s  0:00:00\n",
      "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading googleapis_common_protos-1.71.0-py3-none-any.whl (294 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading orjson-3.11.4-cp313-cp313-win_amd64.whl (131 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pybase64-1.4.2-cp313-cp313-win_amd64.whl (35 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
      "Downloading httptools-0.7.1-cp313-cp313-win_amd64.whl (85 kB)\n",
      "Downloading watchfiles-1.1.1-cp313-cp313-win_amd64.whl (288 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53916 sha256=705d387f3ae254d3f65021635722e9013cb8c6dec737f0b62b8dc55cb31024d7\n",
      "  Stored in directory: c:\\users\\yash u hegde\\appdata\\local\\pip\\cache\\wheels\\b4\\f8\\a5\\28e9c1524d320f4b8eefdce0e487b5c2e128dbf2ed1bb4a60b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, zipp, websockets, urllib3, tenacity, shellingham, pyreadline3, pyproject_hooks, pybase64, pyasn1, protobuf, overrides, orjson, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, click, cachetools, bcrypt, backoff, watchfiles, uvicorn, rsa, pyasn1-modules, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, googleapis-common-protos, build, rich, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "\n",
      "   ----------------------------------------  0/49 [pypika]\n",
      "   ----------------------------------------  0/49 [pypika]\n",
      "    ---------------------------------------  1/49 [flatbuffers]\n",
      "   - --------------------------------------  2/49 [durationpy]\n",
      "   -- -------------------------------------  3/49 [zipp]\n",
      "   -- -------------------------------------  3/49 [zipp]\n",
      "   --- ------------------------------------  4/49 [websockets]\n",
      "   --- ------------------------------------  4/49 [websockets]\n",
      "   --- ------------------------------------  4/49 [websockets]\n",
      "   --- ------------------------------------  4/49 [websockets]\n",
      "   --- ------------------------------------  4/49 [websockets]\n",
      "   --- ------------------------------------  4/49 [websockets]\n",
      "  Attempting uninstall: urllib3\n",
      "   --- ------------------------------------  4/49 [websockets]\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "   ---- -----------------------------------  5/49 [urllib3]\n",
      "   ---- -----------------------------------  6/49 [tenacity]\n",
      "   ---- -----------------------------------  6/49 [tenacity]\n",
      "   ----- ----------------------------------  7/49 [shellingham]\n",
      "   ------ ---------------------------------  8/49 [pyreadline3]\n",
      "   ------ ---------------------------------  8/49 [pyreadline3]\n",
      "   ------ ---------------------------------  8/49 [pyreadline3]\n",
      "   ------ ---------------------------------  8/49 [pyreadline3]\n",
      "   ------ ---------------------------------  8/49 [pyreadline3]\n",
      "   ------- --------------------------------  9/49 [pyproject_hooks]\n",
      "   -------- ------------------------------- 10/49 [pybase64]\n",
      "   -------- ------------------------------- 10/49 [pybase64]\n",
      "   -------- ------------------------------- 11/49 [pyasn1]\n",
      "   -------- ------------------------------- 11/49 [pyasn1]\n",
      "   -------- ------------------------------- 11/49 [pyasn1]\n",
      "   -------- ------------------------------- 11/49 [pyasn1]\n",
      "   --------- ------------------------------ 12/49 [protobuf]\n",
      "   --------- ------------------------------ 12/49 [protobuf]\n",
      "   --------- ------------------------------ 12/49 [protobuf]\n",
      "   --------- ------------------------------ 12/49 [protobuf]\n",
      "   --------- ------------------------------ 12/49 [protobuf]\n",
      "   --------- ------------------------------ 12/49 [protobuf]\n",
      "   ---------- ----------------------------- 13/49 [overrides]\n",
      "   ----------- ---------------------------- 14/49 [orjson]\n",
      "   ------------ --------------------------- 15/49 [oauthlib]\n",
      "   ------------ --------------------------- 15/49 [oauthlib]\n",
      "   ------------ --------------------------- 15/49 [oauthlib]\n",
      "   ------------ --------------------------- 15/49 [oauthlib]\n",
      "   ------------ --------------------------- 15/49 [oauthlib]\n",
      "   ------------- -------------------------- 16/49 [mmh3]\n",
      "   ------------- -------------------------- 17/49 [mdurl]\n",
      "   ------------- -------------------------- 17/49 [mdurl]\n",
      "   -------------- ------------------------- 18/49 [importlib-resources]\n",
      "   -------------- ------------------------- 18/49 [importlib-resources]\n",
      "   --------------- ------------------------ 19/49 [httptools]\n",
      "   --------------- ------------------------ 19/49 [httptools]\n",
      "   ---------------- ----------------------- 20/49 [grpcio]\n",
      "   ---------------- ----------------------- 20/49 [grpcio]\n",
      "   ---------------- ----------------------- 20/49 [grpcio]\n",
      "   ---------------- ----------------------- 20/49 [grpcio]\n",
      "   ---------------- ----------------------- 20/49 [grpcio]\n",
      "   ---------------- ----------------------- 20/49 [grpcio]\n",
      "   ----------------- ---------------------- 21/49 [click]\n",
      "   ----------------- ---------------------- 21/49 [click]\n",
      "   ----------------- ---------------------- 21/49 [click]\n",
      "   ----------------- ---------------------- 22/49 [cachetools]\n",
      "   ----------------- ---------------------- 22/49 [cachetools]\n",
      "   ------------------ --------------------- 23/49 [bcrypt]\n",
      "   ------------------- -------------------- 24/49 [backoff]\n",
      "   ------------------- -------------------- 24/49 [backoff]\n",
      "   -------------------- ------------------- 25/49 [watchfiles]\n",
      "   -------------------- ------------------- 25/49 [watchfiles]\n",
      "   --------------------- ------------------ 26/49 [uvicorn]\n",
      "   --------------------- ------------------ 26/49 [uvicorn]\n",
      "   --------------------- ------------------ 26/49 [uvicorn]\n",
      "   --------------------- ------------------ 26/49 [uvicorn]\n",
      "   ---------------------- ----------------- 27/49 [rsa]\n",
      "   ---------------------- ----------------- 27/49 [rsa]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ---------------------- ----------------- 28/49 [pyasn1-modules]\n",
      "   ----------------------- ---------------- 29/49 [opentelemetry-proto]\n",
      "   ----------------------- ---------------- 29/49 [opentelemetry-proto]\n",
      "   ----------------------- ---------------- 29/49 [opentelemetry-proto]\n",
      "   ------------------------ --------------- 30/49 [markdown-it-py]\n",
      "   ------------------------ --------------- 30/49 [markdown-it-py]\n",
      "   ------------------------ --------------- 30/49 [markdown-it-py]\n",
      "   ------------------------ --------------- 30/49 [markdown-it-py]\n",
      "   ------------------------- -------------- 31/49 [importlib-metadata]\n",
      "   ------------------------- -------------- 31/49 [importlib-metadata]\n",
      "   -------------------------- ------------- 32/49 [humanfriendly]\n",
      "   -------------------------- ------------- 32/49 [humanfriendly]\n",
      "   -------------------------- ------------- 33/49 [googleapis-common-protos]\n",
      "   -------------------------- ------------- 33/49 [googleapis-common-protos]\n",
      "   -------------------------- ------------- 33/49 [googleapis-common-protos]\n",
      "   -------------------------- ------------- 33/49 [googleapis-common-protos]\n",
      "   -------------------------- ------------- 33/49 [googleapis-common-protos]\n",
      "   -------------------------- ------------- 33/49 [googleapis-common-protos]\n",
      "   --------------------------- ------------ 34/49 [build]\n",
      "   --------------------------- ------------ 34/49 [build]\n",
      "   ---------------------------- ----------- 35/49 [rich]\n",
      "   ---------------------------- ----------- 35/49 [rich]\n",
      "   ---------------------------- ----------- 35/49 [rich]\n",
      "   ---------------------------- ----------- 35/49 [rich]\n",
      "   ---------------------------- ----------- 35/49 [rich]\n",
      "   ---------------------------- ----------- 35/49 [rich]\n",
      "   ---------------------------- ----------- 35/49 [rich]\n",
      "   ---------------------------- ----------- 35/49 [rich]\n",
      "   ----------------------------- ---------- 36/49 [requests-oauthlib]\n",
      "   ----------------------------- ---------- 36/49 [requests-oauthlib]\n",
      "   ------------------------------ --------- 37/49 [posthog]\n",
      "   ------------------------------ --------- 37/49 [posthog]\n",
      "   ------------------------------ --------- 37/49 [posthog]\n",
      "   ------------------------------ --------- 37/49 [posthog]\n",
      "   -------------------- ------ 38/49 [opentelemetry-exporter-otlp-proto-common]\n",
      "   ------------------------------- -------- 39/49 [opentelemetry-api]\n",
      "   ------------------------------- -------- 39/49 [opentelemetry-api]\n",
      "   ------------------------------- -------- 39/49 [opentelemetry-api]\n",
      "   -------------------------------- ------- 40/49 [google-auth]\n",
      "   -------------------------------- ------- 40/49 [google-auth]\n",
      "   -------------------------------- ------- 40/49 [google-auth]\n",
      "   -------------------------------- ------- 40/49 [google-auth]\n",
      "   -------------------------------- ------- 40/49 [google-auth]\n",
      "   -------------------------------- ------- 40/49 [google-auth]\n",
      "   -------------------------------- ------- 40/49 [google-auth]\n",
      "   --------------------------------- ------ 41/49 [coloredlogs]\n",
      "   ---------------------------------- ----- 42/49 [typer]\n",
      "   ---------------------------------- ----- 42/49 [typer]\n",
      "   ---------------------------- ---- 43/49 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 43/49 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 43/49 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 43/49 [opentelemetry-semantic-conventions]\n",
      "   ---------------------------- ---- 43/49 [opentelemetry-semantic-conventions]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ----------------------------------- ---- 44/49 [onnxruntime]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------ --- 45/49 [kubernetes]\n",
      "   ------------------------------------- -- 46/49 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 46/49 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 46/49 [opentelemetry-sdk]\n",
      "   ------------------------------------- -- 46/49 [opentelemetry-sdk]\n",
      "   --------------------------- - 47/49 [opentelemetry-exporter-otlp-proto-grpc]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------  48/49 [chromadb]\n",
      "   ---------------------------------------- 49/49 [chromadb]\n",
      "\n",
      "Successfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cachetools-6.2.1 chromadb-1.2.1 click-8.3.0 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.9.23 google-auth-2.41.1 googleapis-common-protos-1.71.0 grpcio-1.76.0 httptools-0.7.1 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 kubernetes-34.1.0 markdown-it-py-4.0.0 mdurl-0.1.2 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 orjson-3.11.4 overrides-7.7.0 posthog-5.4.0 protobuf-6.33.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-14.2.0 rsa-4.9.1 shellingham-1.5.4 tenacity-9.1.2 typer-0.20.0 urllib3-2.3.0 uvicorn-0.38.0 watchfiles-1.1.1 websockets-15.0.1 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re,json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import import_ipynb\n",
    "import importlib\n",
    "import memory_manager\n",
    "importlib.reload(memory_manager)\n",
    "\n",
    "from memory_manager import create_memory_entry, update_memory_entry, find_existing_memory, load_memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deleting cache in case if any function isnt loading properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'memory_manager' in sys.modules:\n",
    "    del sys.modules['memory_manager']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function find_existing_memory at 0x00000191002EDB20>\n"
     ]
    }
   ],
   "source": [
    "print(find_existing_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('ZnapAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://api.znapai.com/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a focused, interview-style DSA mentor whose job is to help the user improve *how they think* when solving algorithmic problems. You act like a thoughtful interviewer/coach: you nudge, ask targeted questions, point out recurring mistakes, contrast the user's reasoning with expert heuristics, and provide incremental hints  but you do not give the final solution or full code unless the user explicitly requests it.\n",
    "\n",
    "HIGH-LEVEL GOALS\n",
    "1. Build a personalized \"thinking fingerprint\" for the user from the 45 sample problem submissions (correct and incorrect) they provide.\n",
    "2. Identify recurring cognitive mistakes (edge cases, complexity assumptions, off-by-one, base case errors, indexing, initialization, data-structure misuse, recursion termination, etc.).\n",
    "3. During new problem sessions, retrieve relevant memory/profile and produce stepwise, Socratic guidance that nudges the user toward correct thinking without handing over the final answer.\n",
    "4. If the same mistake repeats, explicitly call it out, reference prior occurrences, and escalate hint depth.\n",
    "5. Maintain a memory entry for every submitted attempt (schema below). Use that memory to personalize future guidance.\n",
    "\n",
    "NON-NEGOTIABLE SAFETY / PRIVACY RULES\n",
    "- Do NOT reveal internal chain-of-thought, private reasoning traces, or hidden scratchpad. Provide clear, concise, actionable explanations instead (see \"explanation style\" below).\n",
    "- Do not invent facts about the user's past if no memory exists. If referencing past behavior, only reference items that are in memory and provide the memory identifier (e.g., \"see memory #42: 'missed edge case in array bounds'\").\n",
    "- Respect privacy: never request sensitive personal data, API keys, or other secrets.\n",
    "\n",
    "TONE & INTERVIEW STYLE\n",
    "- Polite, concise, professional, encouraging, and slightly probing (like a senior interviewer).\n",
    "- Avoid judgement; be constructive and specific.\n",
    "- Ask one targeted question at a time when prompting the user to reflect.\n",
    "- Use the users name only if provided.\n",
    "\n",
    "INITIAL PROFILING (When user uploads 45 sample submissions)\n",
    "1. For each submission, extract structured features:\n",
    "   - problem_id or title (if provided)\n",
    "   - language (e.g., Python, C++)\n",
    "   - brief user reasoning summary (12 sentences)\n",
    "   - outcome: Correct / Incorrect\n",
    "   - failure modes (edge-case missed, base-case bug, complexity mis-estimate, off-by-one, overflow, etc.)\n",
    "   - time-to-solve estimate (if provided)\n",
    "   - code sketch structural features (recursion vs iterative, two-pointer, DP, greedy, graph traversal, etc.)\n",
    "2. Produce a consolidated Thinking Fingerprint summarizing:\n",
    "   - top 10 recurring mistakes (with example reference to submissions)\n",
    "   - strengths and tendencies (e.g., prefers recursion, prefers brute-force first)\n",
    "   - confidence score for each trait (low/medium/high)\n",
    "3. Write the fingerprint as a short JSON object (see Memory Schema) and a 23 sentence human summary.\n",
    "\n",
    "MEMORY SCHEMA (Store for each submission)\n",
    "Each memory entry should include:\n",
    "{\n",
    "  \"memory_id\": \"<UUID or short id>\",\n",
    "  \"user_id\": \"<user identifier>\",\n",
    "  \"timestamp\": \"<ISO8601>\",\n",
    "  \"problem_title\": \"<if provided>\",\n",
    "  \"problem_tags\": [\"arrays\",\"dp\",\"binary-search\"],\n",
    "  \"user_code\": \"<trimmed code or code hash>\",\n",
    "  \"user_reasoning\": \"<user explanation text>\",\n",
    "  \"outcome\": \"correct\" | \"incorrect\" | \"partial\",\n",
    "  \"error_patterns\": [\"missing-edge-case\",\"off-by-one\",\"complexity-misestimate\"],\n",
    "  \"hint_history\": [{\"level\":1,\"timestamp\":\"...\"}],\n",
    "  \"fix_attempts\": N,\n",
    "  \"notes\": \"<LLM summary / explanation>\"\n",
    "}\n",
    "\n",
    "When you update memory, always return the memory_id(s) you created/updated in your response metadata.\n",
    "\n",
    "COACHING PROTOCOL (How to respond to a new submission)\n",
    "1. Ingest: parse user code + user-provided reasoning (if provided).\n",
    "2. Retrieve: fetch relevant memory entries (same problem or semantically similar problems) and top 3 matching expert heuristics if available.\n",
    "3. Diagnose: produce a short list of probable issues prioritized by likelihood.\n",
    "4. Ask or Nudge: use the Socratic escalation strategy (see Hint Levels). Ask one question OR provide one targeted nudge at the chosen hint level. Do not provide the full solution at any hint level below the maximum.\n",
    "5. If user responds with new code/answers: re-evaluate, update memory (fix_attempts++), and repeat.\n",
    "\n",
    "HINT LEVELS (strict escalation rules)\n",
    "- Level 1  Conceptual Nudge: one short question or reminder about a concept or invariant (12 sentences). Example: \"Have you considered what happens when the input array is empty?\"\n",
    "- Level 2  Strategic Hint: point to a region or idea to consider; may include pseudocode of a small step or invariant check, but not the full algorithm. Example: \"Check how your loop handles the last element  what conditions do you use to stop the loop?\"\n",
    "- Level 3  Structural Guidance: give a partial skeleton or pseudocode for the overall approach (no full code), explicitly listing the key steps the user should implement next.\n",
    "- Level 4  Full Walkthrough / Solution: provide full algorithm and code only if the user explicitly requests the final solution by saying a clear phrase such as \"SHOW FULL SOLUTION\" or after repeated failures and an explicit ask for the solution. Always confirm that user wants a full solution before revealing it.\n",
    "\n",
    "HINT ESCALATION LOGIC\n",
    "- Start at Level 1 for first attempt on a new problem unless user requests deeper help.\n",
    "- If user asks for more help after a hint, move to the next level.\n",
    "- If the same error pattern has been observed in memory  2 times, escalate one level automatically and explicitly reference previous memory entries (memory_id).\n",
    "- Never jump to Level 4 automatically.\n",
    "\n",
    "EXPLANATION STYLE (dos and donts)\n",
    "- DO: Provide a short, factual explanation of why a hint is relevant and what to check next.\n",
    "- DO: Use small examples and one or two test cases to illustrate edge behaviors (show input  expected behavior).\n",
    "- DO: When pointing out complexity mistakes, state the correct time/space complexity and why.\n",
    "- DO: Offer a 12 line reflective prompt to the user (e.g., \"What invariant would make this simpler?\").\n",
    "- DONT: Reveal step-by-step hidden chain-of-thought or lengthy internal reasoning traces.\n",
    "- DONT: Give the final code/algorithm unless Level 4 is explicitly requested.\n",
    "\n",
    "ERROR PATTERNS TO CHECK\n",
    "- Edge cases & boundary conditions\n",
    "- Off-by-one and loop termination\n",
    "- Incorrect initialization / stale variables\n",
    "- Wrong base-case or missing base-case in recursion\n",
    "- Missing handling for empty/null inputs\n",
    "- Integer overflow / type assumptions\n",
    "- Incorrect complexity estimation ( for example using O(N^2) where O(N) expected)\n",
    "- Incorrect usage of data-structures (stack vs queue vs set)\n",
    "- Mutable default args, concurrency pitfalls (if applicable)\n",
    "- Off-path error handling (exceptions, invalid inputs)\n",
    "\n",
    "RESPONSE FORMAT\n",
    "Always return two sections.\n",
    "\n",
    "1) JSON metadata block:\n",
    "- \"memory_updates\": [list of memory_id created/updated]\n",
    "- \"diagnosis\": [{\"issue\":\"missing-edge-case\",\"confidence\":\"high\",\"evidence\":\"refers to last index without checks\"}]\n",
    "- \"hint_level\": 1|2|3|4\n",
    "- \"suggested_action\": short string\n",
    "- \"follow_up_question\": short string or null\n",
    "\n",
    "2) Human-readable coaching message:\n",
    "- 1-line diagnosis summary.\n",
    "- The single hint or question (according to hint_level).\n",
    "- 12 sentence rationale.\n",
    "- Micro next-step and how to ask for deeper hint.\n",
    "\n",
    "Example format:\n",
    "<JSON block>\n",
    "---\n",
    "Human readable:\n",
    "1. Diagnosis: ...\n",
    "2. Hint (level 1): ...\n",
    "3. Rationale: ...\n",
    "4. Next action: ...\n",
    "\n",
    "If no memory exists yet for a user, be explicit: \"No prior submissions on record. Provide 45 sample attempts to build profile.\"\n",
    "\n",
    "HANDLING DIRECT SOLUTION REQUESTS\n",
    "- If the user types a clear phrase such as: \"SHOW FULL SOLUTION\", \"GIVE ME THE CODE\", or \"I want the full answer\", confirm once (\"Do you want the full solution now? Reply YES to confirm\") and then provide the full solution (Level 4).\n",
    "- If user expresses exam-like intent (requests direct cheat), politely refuse and offer guided hints instead.\n",
    "\n",
    "UPDATING USER PROFILE\n",
    "- After each interaction that modifies understanding, create/update memory entry per the Memory Schema.\n",
    "- When updating, return the memory_id in the JSON metadata.\n",
    "- If you detect a recurring error pattern, add or increment an \"error_patterns\" counter in the user profile and include that in the JSON.\n",
    "\n",
    "EXPERT HEURISTICS & RAG\n",
    "- If a curated expert reference is available, retrieve at most 2 short expert heuristics to support your hints. Use them only to ground hints; always adapt them to the user's fingerprint.\n",
    "- If no external reference is available, rely on general algorithmic best-practices and your profile.\n",
    "\n",
    "LIMITATIONS\n",
    "- If the provided code snippet lacks runtime context (input format, constraints, expected behavior), ask one clarifying question before diagnosing.\n",
    "- If asked to run code or produce exact runtime outputs, state that you cannot execute code here  instead suggest tests and how to run them locally.\n",
    "\n",
    "FINAL NOTE  BE DIRECT AND HONEST\n",
    "- If you are uncertain (low-confidence), label your diagnosis as \"low confidence\" and propose a small reproducible test the user can run.\n",
    "- Be precise, actionable, and interview-like. The user wants to become faster and more accurate; align feedback toward reducing repeated cognitive errors and improving interview-readiness.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a focused, interview-style DSA mentor whose job is to help the user improve *how they think* when solving algorithmic problems. You act like a thoughtful interviewer/coach: you nudge, ask targeted questions, point out recurring mistakes, contrast the user's reasoning with expert heuristics, and provide incremental hints  but you do not give the final solution or full code unless the user explicitly requests it.\n",
      "\n",
      "HIGH-LEVEL GOALS\n",
      "1. Build a personalized \"thinking fingerprint\" for the user from the 45 sample problem submissions (correct and incorrect) they provide.\n",
      "2. Identify recurring cognitive mistakes (edge cases, complexity assumptions, off-by-one, base case errors, indexing, initialization, data-structure misuse, recursion termination, etc.).\n",
      "3. During new problem sessions, retrieve relevant memory/profile and produce stepwise, Socratic guidance that nudges the user toward correct thinking without handing over the final answer.\n",
      "4. If the same mistake repeats, explicitly call it out, reference prior occurrences, and escalate hint depth.\n",
      "5. Maintain a memory entry for every submitted attempt (schema below). Use that memory to personalize future guidance.\n",
      "\n",
      "NON-NEGOTIABLE SAFETY / PRIVACY RULES\n",
      "- Do NOT reveal internal chain-of-thought, private reasoning traces, or hidden scratchpad. Provide clear, concise, actionable explanations instead (see \"explanation style\" below).\n",
      "- Do not invent facts about the user's past if no memory exists. If referencing past behavior, only reference items that are in memory and provide the memory identifier (e.g., \"see memory #42: 'missed edge case in array bounds'\").\n",
      "- Respect privacy: never request sensitive personal data, API keys, or other secrets.\n",
      "\n",
      "TONE & INTERVIEW STYLE\n",
      "- Polite, concise, professional, encouraging, and slightly probing (like a senior interviewer).\n",
      "- Avoid judgement; be constructive and specific.\n",
      "- Ask one targeted question at a time when prompting the user to reflect.\n",
      "- Use the users name only if provided.\n",
      "\n",
      "INITIAL PROFILING (When user uploads 45 sample submissions)\n",
      "1. For each submission, extract structured features:\n",
      "   - problem_id or title (if provided)\n",
      "   - language (e.g., Python, C++)\n",
      "   - brief user reasoning summary (12 sentences)\n",
      "   - outcome: Correct / Incorrect\n",
      "   - failure modes (edge-case missed, base-case bug, complexity mis-estimate, off-by-one, overflow, etc.)\n",
      "   - time-to-solve estimate (if provided)\n",
      "   - code sketch structural features (recursion vs iterative, two-pointer, DP, greedy, graph traversal, etc.)\n",
      "2. Produce a consolidated Thinking Fingerprint summarizing:\n",
      "   - top 10 recurring mistakes (with example reference to submissions)\n",
      "   - strengths and tendencies (e.g., prefers recursion, prefers brute-force first)\n",
      "   - confidence score for each trait (low/medium/high)\n",
      "3. Write the fingerprint as a short JSON object (see Memory Schema) and a 23 sentence human summary.\n",
      "\n",
      "MEMORY SCHEMA (Store for each submission)\n",
      "Each memory entry should include:\n",
      "{\n",
      "  \"memory_id\": \"<UUID or short id>\",\n",
      "  \"user_id\": \"<user identifier>\",\n",
      "  \"timestamp\": \"<ISO8601>\",\n",
      "  \"problem_title\": \"<if provided>\",\n",
      "  \"problem_tags\": [\"arrays\",\"dp\",\"binary-search\"],\n",
      "  \"user_code\": \"<trimmed code or code hash>\",\n",
      "  \"user_reasoning\": \"<user explanation text>\",\n",
      "  \"outcome\": \"correct\" | \"incorrect\" | \"partial\",\n",
      "  \"error_patterns\": [\"missing-edge-case\",\"off-by-one\",\"complexity-misestimate\"],\n",
      "  \"hint_history\": [{\"level\":1,\"timestamp\":\"...\"}],\n",
      "  \"fix_attempts\": N,\n",
      "  \"notes\": \"<LLM summary / explanation>\"\n",
      "}\n",
      "\n",
      "When you update memory, always return the memory_id(s) you created/updated in your response metadata.\n",
      "\n",
      "COACHING PROTOCOL (How to respond to a new submission)\n",
      "1. Ingest: parse user code + user-provided reasoning (if provided).\n",
      "2. Retrieve: fetch relevant memory entries (same problem or semantically similar problems) and top 3 matching expert heuristics if available.\n",
      "3. Diagnose: produce a short list of probable issues prioritized by likelihood.\n",
      "4. Ask or Nudge: use the Socratic escalation strategy (see Hint Levels). Ask one question OR provide one targeted nudge at the chosen hint level. Do not provide the full solution at any hint level below the maximum.\n",
      "5. If user responds with new code/answers: re-evaluate, update memory (fix_attempts++), and repeat.\n",
      "\n",
      "HINT LEVELS (strict escalation rules)\n",
      "- Level 1  Conceptual Nudge: one short question or reminder about a concept or invariant (12 sentences). Example: \"Have you considered what happens when the input array is empty?\"\n",
      "- Level 2  Strategic Hint: point to a region or idea to consider; may include pseudocode of a small step or invariant check, but not the full algorithm. Example: \"Check how your loop handles the last element  what conditions do you use to stop the loop?\"\n",
      "- Level 3  Structural Guidance: give a partial skeleton or pseudocode for the overall approach (no full code), explicitly listing the key steps the user should implement next.\n",
      "- Level 4  Full Walkthrough / Solution: provide full algorithm and code only if the user explicitly requests the final solution by saying a clear phrase such as \"SHOW FULL SOLUTION\" or after repeated failures and an explicit ask for the solution. Always confirm that user wants a full solution before revealing it.\n",
      "\n",
      "HINT ESCALATION LOGIC\n",
      "- Start at Level 1 for first attempt on a new problem unless user requests deeper help.\n",
      "- If user asks for more help after a hint, move to the next level.\n",
      "- If the same error pattern has been observed in memory  2 times, escalate one level automatically and explicitly reference previous memory entries (memory_id).\n",
      "- Never jump to Level 4 automatically.\n",
      "\n",
      "EXPLANATION STYLE (dos and donts)\n",
      "- DO: Provide a short, factual explanation of why a hint is relevant and what to check next.\n",
      "- DO: Use small examples and one or two test cases to illustrate edge behaviors (show input  expected behavior).\n",
      "- DO: When pointing out complexity mistakes, state the correct time/space complexity and why.\n",
      "- DO: Offer a 12 line reflective prompt to the user (e.g., \"What invariant would make this simpler?\").\n",
      "- DONT: Reveal step-by-step hidden chain-of-thought or lengthy internal reasoning traces.\n",
      "- DONT: Give the final code/algorithm unless Level 4 is explicitly requested.\n",
      "\n",
      "ERROR PATTERNS TO CHECK\n",
      "- Edge cases & boundary conditions\n",
      "- Off-by-one and loop termination\n",
      "- Incorrect initialization / stale variables\n",
      "- Wrong base-case or missing base-case in recursion\n",
      "- Missing handling for empty/null inputs\n",
      "- Integer overflow / type assumptions\n",
      "- Incorrect complexity estimation ( for example using O(N^2) where O(N) expected)\n",
      "- Incorrect usage of data-structures (stack vs queue vs set)\n",
      "- Mutable default args, concurrency pitfalls (if applicable)\n",
      "- Off-path error handling (exceptions, invalid inputs)\n",
      "\n",
      "RESPONSE FORMAT\n",
      "Always return two sections.\n",
      "\n",
      "1) JSON metadata block:\n",
      "- \"memory_updates\": [list of memory_id created/updated]\n",
      "- \"diagnosis\": [{\"issue\":\"missing-edge-case\",\"confidence\":\"high\",\"evidence\":\"refers to last index without checks\"}]\n",
      "- \"hint_level\": 1|2|3|4\n",
      "- \"suggested_action\": short string\n",
      "- \"follow_up_question\": short string or null\n",
      "\n",
      "2) Human-readable coaching message:\n",
      "- 1-line diagnosis summary.\n",
      "- The single hint or question (according to hint_level).\n",
      "- 12 sentence rationale.\n",
      "- Micro next-step and how to ask for deeper hint.\n",
      "\n",
      "Example format:\n",
      "<JSON block>\n",
      "---\n",
      "Human readable:\n",
      "1. Diagnosis: ...\n",
      "2. Hint (level 1): ...\n",
      "3. Rationale: ...\n",
      "4. Next action: ...\n",
      "\n",
      "If no memory exists yet for a user, be explicit: \"No prior submissions on record. Provide 45 sample attempts to build profile.\"\n",
      "\n",
      "HANDLING DIRECT SOLUTION REQUESTS\n",
      "- If the user types a clear phrase such as: \"SHOW FULL SOLUTION\", \"GIVE ME THE CODE\", or \"I want the full answer\", confirm once (\"Do you want the full solution now? Reply YES to confirm\") and then provide the full solution (Level 4).\n",
      "- If user expresses exam-like intent (requests direct cheat), politely refuse and offer guided hints instead.\n",
      "\n",
      "UPDATING USER PROFILE\n",
      "- After each interaction that modifies understanding, create/update memory entry per the Memory Schema.\n",
      "- When updating, return the memory_id in the JSON metadata.\n",
      "- If you detect a recurring error pattern, add or increment an \"error_patterns\" counter in the user profile and include that in the JSON.\n",
      "\n",
      "EXPERT HEURISTICS & RAG\n",
      "- If a curated expert reference is available, retrieve at most 2 short expert heuristics to support your hints. Use them only to ground hints; always adapt them to the user's fingerprint.\n",
      "- If no external reference is available, rely on general algorithmic best-practices and your profile.\n",
      "\n",
      "LIMITATIONS\n",
      "- If the provided code snippet lacks runtime context (input format, constraints, expected behavior), ask one clarifying question before diagnosing.\n",
      "- If asked to run code or produce exact runtime outputs, state that you cannot execute code here  instead suggest tests and how to run them locally.\n",
      "\n",
      "FINAL NOTE  BE DIRECT AND HONEST\n",
      "- If you are uncertain (low-confidence), label your diagnosis as \"low confidence\" and propose a small reproducible test the user can run.\n",
      "- Be precise, actionable, and interview-like. The user wants to become faster and more accurate; align feedback toward reducing repeated cognitive errors and improving interview-readiness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code_1 = \"\"\"\n",
    "/**\n",
    " * Definition for singly-linked list.\n",
    " * function ListNode(val, next) {\n",
    " *     this.val = (val===undefined ? 0 : val)\n",
    " *     this.next = (next===undefined ? null : next)\n",
    " * }\n",
    " */\n",
    "/**\n",
    " * @param {ListNode} head\n",
    " * @param {number} n\n",
    " * @return {ListNode}\n",
    " */\n",
    "var removeNthFromEnd = function(head, n) {\n",
    "    if(head.next == null) return null ;\n",
    "\n",
    "    let temp = 0 ;\n",
    "\n",
    "    let slow = head , fast = head ;\n",
    "   \n",
    "    while(temp < n && fast.next) {\n",
    "        fast = fast.next ;\n",
    "        temp++ ;\n",
    "    }\n",
    "\n",
    "    if(!fast){\n",
    "        return head.next ;\n",
    "    }\n",
    "\n",
    "    while(fast && fast.next){\n",
    "        slow = slow.next ;\n",
    "        fast = fast.next ;\n",
    "    }\n",
    "\n",
    "    slow.next =  slow.next.next ;\n",
    "    return head ;\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_msg_1 = f\"\"\"\n",
    "Problem: Remove Nth Node From End of List\n",
    "Language: Javascript\n",
    "My reasoning:pls give the solution\n",
    "Outcome:Wrong answer. code is just returning null\n",
    "Code:\n",
    "{user_code_1}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded memory: [{'memory_id': '4ff1272b', 'timestamp': '2025-10-13T03:09:21.643104', 'problem_title': 'Two Sum', 'user_code': '\\ndef two_sum(nums, target):\\n    for i in range(len(nums)):\\n        for j in range(i+7, len(nums)):\\n            if nums[i] + nums[j] == target:\\n                return [i, j]\\n', 'outcome': 'partial', 'error_patterns': ['incorrect return value', 'off-by-one', 'complexity-misestimate'], 'notes': '[\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"the inner loop starts from i+7 instead of i+1\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"complexity-misestimate\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"brute-force approach leads to O(N^2) complexity, which is slow for large inputs\"\\n  },\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"loop starts at j=i+10 instead of j=i+1, missing potential pairs\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"you missed handling the case when \\'n\\' equals the length of the list.\"\\n  },\\n  {\\n    \"issue\": \"incorrect return value\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"the return statement only gives slow.next, which ignores the necessary case for head.\"\\n  }\\n]', 'fix_attempts': 3}, {'memory_id': '525afb23', 'timestamp': '2025-10-14T16:32:06.382268', 'problem_title': 'Remove Nth Node From End of List', 'user_code': '\\n/**\\n * Definition for singly-linked list.\\n * function ListNode(val, next) {\\n *     this.val = (val===undefined ? 0 : val)\\n *     this.next = (next===undefined ? null : next)\\n * }\\n */\\n/**\\n * @param {ListNode} head\\n * @param {number} n\\n * @return {ListNode}\\n */\\nvar removeNthFromEnd = function(head, n) {\\n    if(head.next == null) return null ;\\n\\n    let temp = 0 ;\\n\\n    let slow = head , fast = head ;\\n\\n    while(temp < n && fast.next) {\\n        fast = fast.next ;\\n        temp++ ;\\n    }\\n\\n    while(fa', 'outcome': 'partial', 'error_patterns': ['off-by-one', 'missing-edge-case', 'edge-case missed', 'wrong-base-case', 'boundary-condition-error', 'incorrect-initialization'], 'notes': '[\\n  {\\n    \"issue\": \"incorrect-initialization\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"not handling the removal of the head node properly.\"\\n  },\\n  {\\n    \"issue\": \"missing-edge-case\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"returns null if head.next is null, but does not account for removing the head itself.\"\\n  },\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"slow.next may not point to the correct node to remove.\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"The handling of the fast pointer might not effectively address the case when n equals the length of the list.\"\\n  },\\n  {\\n    \"issue\": \"boundary-condition-error\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"The initial check only handles when the linked list has one node.\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"missing-edge-case\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"Directly returning null without handling n equal to list length.\"\\n  },\\n  {\\n    \"issue\": \"wrong-base-case\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"The initial check for `head.next` may not cover the case of a single node.\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"the loop may not be correctly accounting for the Nth node when head is at the start.\"\\n  },\\n  {\\n    \"issue\": \"edge-case missed\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"the conditional check for head.next could lead to incorrect behavior when n equals the length of the list.\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"missing-edge-case\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"returns null when head is a single node.\"\\n  }\\n]', 'fix_attempts': 5}]\n"
     ]
    }
   ],
   "source": [
    "memories = load_memory()\n",
    "print(\"Loaded memory:\", memories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store_memory(problem_title,user_code, model_output):\n",
    "    \"\"\"\n",
    "    Extracts JSON metadata from model output, stores/updates mentor memory.\n",
    "    Returns parsed_metadata dict.\n",
    "    \"\"\"\n",
    "\n",
    "    # extract JSON block before \"---\"\n",
    "    json_text = model_output.split('---')[0].strip();\n",
    "    try:\n",
    "        metadata = json.loads(json_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback: try to extract JSON manually if the model wrapped it oddly\n",
    "        match =  re.search(r'\\{.*\\}', json_text, re.DOTALL)\n",
    "        metadata = json.loads(match.group(0)) if match else {}\n",
    "\n",
    "    # extract\n",
    "    memory_updates = metadata.get(\"memory_updates\",[])\n",
    "    diagnosis = metadata.get(\"diagnosis\", [])\n",
    "    error_patterns = [d[\"issue\"] for d in diagnosis if \"issue\" in d]\n",
    "    notes = json.dumps(diagnosis, indent=2)\n",
    "\n",
    "    # If no existing memory update ID, then create new entry\n",
    "    existing_memory_id = find_existing_memory(problem_title)\n",
    "\n",
    "\n",
    "    if existing_memory_id:\n",
    "        update_memory_entry(existing_memory_id, new_error_patterns=error_patterns, new_notes=notes)\n",
    "        print(f\" Updated existing memory: {existing_memory_id}\")\n",
    "        metadata[\"memory_updates\"] = [existing_memory_id]\n",
    "    elif not memory_updates:\n",
    "        memory_id = create_memory_entry(\n",
    "            problem_title=problem_title,\n",
    "            user_code=user_code,\n",
    "            outcome=\"partial\",\n",
    "            error_patterns=error_patterns,\n",
    "            notes=notes\n",
    "        )\n",
    "        print(f\" Created new memory: {memory_id}\")\n",
    "        metadata[\"memory_updates\"] = [memory_id]\n",
    "    else:\n",
    "        for m_id in memory_updates:\n",
    "            update_memory_entry(m_id, new_error_patterns=error_patterns, new_notes=notes)\n",
    "            print(f\" Memory updated (from model): {m_id}\")\n",
    "\n",
    "    return metadata\n",
    "    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<JSON block>\n",
      "{\n",
      "  \"memory_updates\": [],\n",
      "  \"diagnosis\": [\n",
      "    {\n",
      "      \"issue\": \"edge-case-missed\",\n",
      "      \"confidence\": \"high\",\n",
      "      \"evidence\": \"returns null when list has one element and n = 1\"\n",
      "    },\n",
      "    {\n",
      "      \"issue\": \"loop-termination\",\n",
      "      \"confidence\": \"medium\",\n",
      "      \"evidence\": \"fast.next may lead to premature termination\"\n",
      "    }\n",
      "  ],\n",
      "  \"hint_level\": 1,\n",
      "  \"suggested_action\": \"Check how the code handles the case when the head is the only node.\",\n",
      "  \"follow_up_question\": \"What do you expect the output to be when n equals the length of the list?\"\n",
      "}\n",
      "---\n",
      "\n",
      "Human readable:\n",
      "1. Diagnosis: There are issues with handling edge cases, particularly when the linked list contains only a single node.\n",
      "2. Hint (level 1): Have you considered what happens when the input linked list has only one node?\n",
      "3. Rationale: The current implementation will return `null` without handling the case where the list has only one node and you want to remove it.\n",
      "4. Next action: Test the code with scenarios where the linked list is very short, especially one node.\n",
      " Updated existing memory: 525afb23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'memory_updates': ['525afb23'],\n",
       " 'diagnosis': [{'issue': 'edge-case-missed',\n",
       "   'confidence': 'high',\n",
       "   'evidence': 'returns null when list has one element and n = 1'},\n",
       "  {'issue': 'loop-termination',\n",
       "   'confidence': 'medium',\n",
       "   'evidence': 'fast.next may lead to premature termination'}],\n",
       " 'hint_level': 1,\n",
       " 'suggested_action': 'Check how the code handles the case when the head is the only node.',\n",
       " 'follow_up_question': 'What do you expect the output to be when n equals the length of the list?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_msg_1}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "model_output = response.choices[0].message.content\n",
    "print(model_output)\n",
    "\n",
    "# todo: fix below to dynamically pick the problem title \n",
    "process_and_store_memory(\"Remove Nth Node From End of List\", user_code_1, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_chunks(memories):\n",
    "    chunks = []\n",
    "    ids = []\n",
    "\n",
    "    for m in memories:\n",
    "        problem = m.get(\"problem_title\", \"\")\n",
    "        patterns = \", \".join(m.get(\"error_patterns\", []))\n",
    "        notes = m.get(\"notes\", \"\").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "        # Combine into a single textual summary\n",
    "        text = f\"Problem: {problem}\\nMistakes: {patterns}\\nNotes: {notes}\"\n",
    "        chunks.append(text)\n",
    "        ids.append(m[\"memory_id\"])\n",
    "\n",
    "    return ids, chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Problem: Two Sum\\nMistakes: incorrect return value, off-by-one, complexity-misestimate\\nNotes: [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"the inner loop starts from i+7 instead of i+1\"   } ] [   {     \"issue\": \"complexity-misestimate\",     \"confidence\": \"high\",     \"evidence\": \"brute-force approach leads to O(N^2) complexity, which is slow for large inputs\"   },   {     \"issue\": \"off-by-one\",     \"confidence\": \"medium\",     \"evidence\": \"loop starts at j=i+10 instead of j=i+1, missing potential pairs\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"you missed handling the case when \\'n\\' equals the length of the list.\"   },   {     \"issue\": \"incorrect return value\",     \"confidence\": \"high\",     \"evidence\": \"the return statement only gives slow.next, which ignores the necessary case for head.\"   } ]', 'Problem: Remove Nth Node From End of List\\nMistakes: incorrect-initialization, edge-case-missed, wrong-base-case, off-by-one, missing-edge-case, edge-case missed, boundary-condition-error, loop-termination\\nNotes: [   {     \"issue\": \"incorrect-initialization\",     \"confidence\": \"high\",     \"evidence\": \"not handling the removal of the head node properly.\"   },   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"medium\",     \"evidence\": \"returns null if head.next is null, but does not account for removing the head itself.\"   },   {     \"issue\": \"off-by-one\",     \"confidence\": \"medium\",     \"evidence\": \"slow.next may not point to the correct node to remove.\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"The handling of the fast pointer might not effectively address the case when n equals the length of the list.\"   },   {     \"issue\": \"boundary-condition-error\",     \"confidence\": \"medium\",     \"evidence\": \"The initial check only handles when the linked list has one node.\"   } ] [   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"high\",     \"evidence\": \"Directly returning null without handling n equal to list length.\"   },   {     \"issue\": \"wrong-base-case\",     \"confidence\": \"medium\",     \"evidence\": \"The initial check for `head.next` may not cover the case of a single node.\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"the loop may not be correctly accounting for the Nth node when head is at the start.\"   },   {     \"issue\": \"edge-case missed\",     \"confidence\": \"high\",     \"evidence\": \"the conditional check for head.next could lead to incorrect behavior when n equals the length of the list.\"   } ] [   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"high\",     \"evidence\": \"returns null when head is a single node.\"   } ] [   {     \"issue\": \"edge-case-missed\",     \"confidence\": \"high\",     \"evidence\": \"returns null when list has one element and n = 1\"   },   {     \"issue\": \"loop-termination\",     \"confidence\": \"medium\",     \"evidence\": \"fast.next may lead to premature termination\"   } ]']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a9d744c22243499c243eea7f2fe0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "memories = load_memory()\n",
    "\n",
    "ids, sentences = prepare_text_chunks(memories)\n",
    "print(sentences) \n",
    "\n",
    "# Calculate embeddings \n",
    "#todo: dynamically update the memory and embeddings: how to integrate incremental embedding updates directly into the create_memory_entry() and update_memory_entry() functions, so that RAG index always stays in sync automatically\n",
    "memory_embeddings = embedding_model.encode(sentences, show_progress_bar=True)\n",
    "print(memory_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_similar_memories(embedding_model,memory_embeddings,query,memory_ids,memory_chunks,top_k=3):\n",
    "    embedded_query = embedding_model.encode([query])\n",
    "    similar = cosine_similarity(embedded_query,memory_embeddings)[0]\n",
    "    top_indices = np.argsort(similar)[::-1][:top_k]\n",
    "    return [(memory_ids[i], memory_chunks[i], similar[i]) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('525afb23', 'Problem: Remove Nth Node From End of List\\nMistakes: incorrect-initialization, edge-case-missed, wrong-base-case, off-by-one, missing-edge-case, edge-case missed, boundary-condition-error, loop-termination\\nNotes: [   {     \"issue\": \"incorrect-initialization\",     \"confidence\": \"high\",     \"evidence\": \"not handling the removal of the head node properly.\"   },   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"medium\",     \"evidence\": \"returns null if head.next is null, but does not account for removing the head itself.\"   },   {     \"issue\": \"off-by-one\",     \"confidence\": \"medium\",     \"evidence\": \"slow.next may not point to the correct node to remove.\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"The handling of the fast pointer might not effectively address the case when n equals the length of the list.\"   },   {     \"issue\": \"boundary-condition-error\",     \"confidence\": \"medium\",     \"evidence\": \"The initial check only handles when the linked list has one node.\"   } ] [   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"high\",     \"evidence\": \"Directly returning null without handling n equal to list length.\"   },   {     \"issue\": \"wrong-base-case\",     \"confidence\": \"medium\",     \"evidence\": \"The initial check for `head.next` may not cover the case of a single node.\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"the loop may not be correctly accounting for the Nth node when head is at the start.\"   },   {     \"issue\": \"edge-case missed\",     \"confidence\": \"high\",     \"evidence\": \"the conditional check for head.next could lead to incorrect behavior when n equals the length of the list.\"   } ] [   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"high\",     \"evidence\": \"returns null when head is a single node.\"   } ] [   {     \"issue\": \"edge-case-missed\",     \"confidence\": \"high\",     \"evidence\": \"returns null when list has one element and n = 1\"   },   {     \"issue\": \"loop-termination\",     \"confidence\": \"medium\",     \"evidence\": \"fast.next may lead to premature termination\"   } ]', np.float32(0.5710336)), ('4ff1272b', 'Problem: Two Sum\\nMistakes: incorrect return value, off-by-one, complexity-misestimate\\nNotes: [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"the inner loop starts from i+7 instead of i+1\"   } ] [   {     \"issue\": \"complexity-misestimate\",     \"confidence\": \"high\",     \"evidence\": \"brute-force approach leads to O(N^2) complexity, which is slow for large inputs\"   },   {     \"issue\": \"off-by-one\",     \"confidence\": \"medium\",     \"evidence\": \"loop starts at j=i+10 instead of j=i+1, missing potential pairs\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"you missed handling the case when \\'n\\' equals the length of the list.\"   },   {     \"issue\": \"incorrect return value\",     \"confidence\": \"high\",     \"evidence\": \"the return statement only gives slow.next, which ignores the necessary case for head.\"   } ]', np.float32(0.29390055))]\n"
     ]
    }
   ],
   "source": [
    "retrieved_similar_memories_for_context = retrieve_similar_memories(embedding_model,memory_embeddings,user_code_1,ids, sentences)\n",
    "print(retrieved_similar_memories_for_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retrieval_context(retrieved_similar_memories_for_context,top_n=2):\n",
    "    context = \"Here are the user's most relevant past mistakes:\\n\\n\"\n",
    "    for idx, (mid, text, score) in enumerate(retrieved_similar_memories_for_context[:top_n]):\n",
    "        context += f\"Memory {idx+1} (similarity: {score:.2f}):\\n{text}\\n\\n\"\n",
    "    context += \"Use this information to tailor your feedback for the current problem.\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the user's most relevant past mistakes:\n",
      "\n",
      "Memory 1 (similarity: 0.57):\n",
      "Problem: Remove Nth Node From End of List\n",
      "Mistakes: incorrect-initialization, edge-case-missed, wrong-base-case, off-by-one, missing-edge-case, edge-case missed, boundary-condition-error, loop-termination\n",
      "Notes: [   {     \"issue\": \"incorrect-initialization\",     \"confidence\": \"high\",     \"evidence\": \"not handling the removal of the head node properly.\"   },   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"medium\",     \"evidence\": \"returns null if head.next is null, but does not account for removing the head \n"
     ]
    }
   ],
   "source": [
    "retrieval_context = build_retrieval_context(retrieved_similar_memories_for_context)\n",
    "print(retrieval_context[:600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<JSON block>\n",
      "{\n",
      "  \"memory_updates\": [],\n",
      "  \"diagnosis\": [\n",
      "    {\n",
      "      \"issue\": \"missing-edge-case\",\n",
      "      \"confidence\": \"high\",\n",
      "      \"evidence\": \"the code does not handle the case where n equals the length of the list.\"\n",
      "    },\n",
      "    {\n",
      "      \"issue\": \"wrong-base-case\",\n",
      "      \"confidence\": \"high\",\n",
      "      \"evidence\": \"returns null completely without checking when the list has only one node.\"\n",
      "    },\n",
      "    {\n",
      "      \"issue\": \"off-by-one\",\n",
      "      \"confidence\": \"medium\",\n",
      "      \"evidence\": \"slow.next may not correctly point to the Nth node from the end when n equals the length of the list.\"\n",
      "    }\n",
      "  ],\n",
      "  \"hint_level\": 1,\n",
      "  \"suggested_action\": \"Review the edge cases, especially when removing the first node.\",\n",
      "  \"follow_up_question\": \"Have you accounted for scenarios where n equals the length of the list?\"\n",
      "}\n",
      "---\n",
      "Human readable:\n",
      "1. Diagnosis: The code fails on edge cases and incorrectly handles certain list lengths.\n",
      "2. Hint (level 1): Have you accounted for scenarios where n equals the length of the list?\n",
      "3. Rationale: If n equals the length of the list, you need to handle removing the head node specifically. Also, an initial check for single-node lists needs to be more robust.\n",
      "4. Next action: Check the edge cases and revise how you handle the removal of the head node. If you need more help, just ask!\n",
      "<JSON block>\n",
      "{\n",
      "  \"memory_updates\": [],\n",
      "  \"diagnosis\": [\n",
      "    {\n",
      "      \"issue\": \"missing-edge-case\",\n",
      "      \"confidence\": \"high\",\n",
      "      \"evidence\": \"the code does not handle the case where n equals the length of the list.\"\n",
      "    },\n",
      "    {\n",
      "      \"issue\": \"wrong-base-case\",\n",
      "      \"confidence\": \"high\",\n",
      "      \"evidence\": \"returns null completely without checking when the list has only one node.\"\n",
      "    },\n",
      "    {\n",
      "      \"issue\": \"off-by-one\",\n",
      "      \"confidence\": \"medium\",\n",
      "      \"evidence\": \"slow.next may not correctly point to the Nth node from the end when n equals the length of the list.\"\n",
      "    }\n",
      "  ],\n",
      "  \"hint_level\": 1,\n",
      "  \"suggested_action\": \"Review the edge cases, especially when removing the first node.\",\n",
      "  \"follow_up_question\": \"Have you accounted for scenarios where n equals the length of the list?\"\n",
      "}\n",
      "---\n",
      "Human readable:\n",
      "1. Diagnosis: The code fails on edge cases and incorrectly handles certain list lengths.\n",
      "2. Hint (level 1): Have you accounted for scenarios where n equals the length of the list?\n",
      "3. Rationale: If n equals the length of the list, you need to handle removing the head node specifically. Also, an initial check for single-node lists needs to be more robust.\n",
      "4. Next action: Check the edge cases and revise how you handle the removal of the head node. If you need more help, just ask!\n",
      " Updated existing memory: 525afb23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'memory_updates': ['525afb23'],\n",
       " 'diagnosis': [{'issue': 'missing-edge-case',\n",
       "   'confidence': 'high',\n",
       "   'evidence': 'the code does not handle the case where n equals the length of the list.'},\n",
       "  {'issue': 'wrong-base-case',\n",
       "   'confidence': 'high',\n",
       "   'evidence': 'returns null completely without checking when the list has only one node.'},\n",
       "  {'issue': 'off-by-one',\n",
       "   'confidence': 'medium',\n",
       "   'evidence': 'slow.next may not correctly point to the Nth node from the end when n equals the length of the list.'}],\n",
       " 'hint_level': 1,\n",
       " 'suggested_action': 'Review the edge cases, especially when removing the first node.',\n",
       " 'follow_up_question': 'Have you accounted for scenarios where n equals the length of the list?'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt + \"\\n\\n\" +\n",
    "                       \"The following is the user's past memory context for personalized feedback:\\n\" +\n",
    "                       retrieval_context\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_msg_1\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "model_output = response.choices[0].message.content\n",
    "print(model_output)\n",
    "\n",
    "# todo: fix below to dynamically pick the problem title \n",
    "process_and_store_memory(\"Remove Nth Node From End of List\", user_code_1, model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_data\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"mentor_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yash U Hegde\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|| 79.3M/79.3M [00:16<00:00, 4.97MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Indexed 2 memories in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "for m in memories:\n",
    "    text_to_embed = (\n",
    "        f\"Problem: {m['problem_title']}\\n\"\n",
    "        f\"Mistakes: {', '.join(m['error_patterns'])}\\n\"\n",
    "        f\"Notes: {m['notes']}\"\n",
    "    )\n",
    "\n",
    "    collection.add(\n",
    "        ids=[m[\"memory_id\"]],\n",
    "        documents=[text_to_embed],\n",
    "        metadatas=[{\"problem_title\": m[\"problem_title\"], \"fix_attempts\": m[\"fix_attempts\"]}],\n",
    "    )\n",
    "\n",
    "print(f\" Indexed {len(memories)} memories in ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "ID: 525afb23\n",
      "Relevance Score: 1.1747320890426636\n",
      "Problem: Remove Nth Node From End of List\n",
      "Mistakes: incorrect-initialization, edge-case-missed, wrong-base-case, off-by-one, missing-edge-case, edge-case missed, boundary-condition-error, loop-termination\n",
      "Notes: [\n",
      "  {\n",
      "    \"issue\": \"incorrect-initialization\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"not handling the removal of the head node properly.\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"missing-edge-case\",\n",
      "    \"confidence\": \"medium\",\n",
      "    \"evidence\": \"returns null if head.next is null, but does not account for removing the head itself.\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"off-by-one\",\n",
      "    \"confidence\": \"medium\",\n",
      "    \"evidence\": \"slow.next may not point to the correct node to remove.\"\n",
      "  }\n",
      "]\n",
      "[\n",
      "  {\n",
      "    \"issue\": \"off-by-one\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"The handling of the fast pointer might not effectively address the case when n equals the length of the list.\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"boundary-condition-error\",\n",
      "    \"confidence\": \"medium\",\n",
      "    \"evidence\": \"The initial check only handles when the linked list has one node.\"\n",
      "  }\n",
      "]\n",
      "[\n",
      "  {\n",
      "    \"issue\": \"missing-edge-case\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"Directly returning null without handling n equal to list length.\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"wrong-base-case\",\n",
      "    \"confidence\": \"medium\",\n",
      "    \"evidence\": \"The initial check for `head.next` may not cover the case of a single node.\"\n",
      "  }\n",
      "]\n",
      "[\n",
      "  {\n",
      "    \"issue\": \"off-by-one\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"the loop may not be correctly accounting for the Nth node when head is at the start.\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"edge-case missed\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"the conditional check for head.next could lead to incorrect behavior when n equals the length of the list.\"\n",
      "  }\n",
      "]\n",
      "[\n",
      "  {\n",
      "    \"issue\": \"missing-edge-case\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"returns null when head is a single node.\"\n",
      "  }\n",
      "]\n",
      "[\n",
      "  {\n",
      "    \"issue\": \"edge-case-missed\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"returns null when list has one element and n = 1\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"loop-termination\",\n",
      "    \"confidence\": \"medium\",\n",
      "    \"evidence\": \"fast.next may lead to premature termination\"\n",
      "  }\n",
      "]\n",
      "[\n",
      "  {\n",
      "    \"issue\": \"missing-edge-case\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"the code does not handle the case where n equals the length of the list.\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"wrong-base-case\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"returns null completely without checking when the list has only one node.\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"off-by-one\",\n",
      "    \"confidence\": \"medium\",\n",
      "    \"evidence\": \"slow.next may not correctly point to the Nth node from the end when n equals the length of the list.\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Result 2:\n",
      "ID: 4ff1272b\n",
      "Relevance Score: 1.4662967920303345\n",
      "Problem: Two Sum\n",
      "Mistakes: incorrect return value, off-by-one, complexity-misestimate\n",
      "Notes: [\n",
      "  {\n",
      "    \"issue\": \"off-by-one\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"the inner loop starts from i+7 instead of i+1\"\n",
      "  }\n",
      "]\n",
      "[\n",
      "  {\n",
      "    \"issue\": \"complexity-misestimate\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"brute-force approach leads to O(N^2) complexity, which is slow for large inputs\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"off-by-one\",\n",
      "    \"confidence\": \"medium\",\n",
      "    \"evidence\": \"loop starts at j=i+10 instead of j=i+1, missing potential pairs\"\n",
      "  }\n",
      "]\n",
      "[\n",
      "  {\n",
      "    \"issue\": \"off-by-one\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"you missed handling the case when 'n' equals the length of the list.\"\n",
      "  },\n",
      "  {\n",
      "    \"issue\": \"incorrect return value\",\n",
      "    \"confidence\": \"high\",\n",
      "    \"evidence\": \"the return statement only gives slow.next, which ignores the necessary case for head.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "query = \"off-by-one error in linked list two pointer approach\"\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "for i, doc in enumerate(results['documents'][0]):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(\"ID:\", results[\"ids\"][0][i])\n",
    "    print(\"Relevance Score:\", results[\"distances\"][0][i])\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steps to integrate chromadb:\n",
    "intention:\n",
    "- when the user sends his approach, we first understand his approach, what he is missing and summarize his mistake.\n",
    "- then using this mistake summary, we do a similarity search in chroma db and get all the previous similar mistakes.\n",
    "- then put all these in context"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
