{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: openai in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (2.12.0)\n",
      "Requirement already satisfied: sniffio in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re,json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import import_ipynb\n",
    "import importlib\n",
    "import memory_manager\n",
    "importlib.reload(memory_manager)\n",
    "\n",
    "from memory_manager import create_memory_entry, update_memory_entry, find_existing_memory, load_memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deleting cache in case if any function isnt loading properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'memory_manager' in sys.modules:\n",
    "    del sys.modules['memory_manager']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function find_existing_memory at 0x0000022A6A002160>\n"
     ]
    }
   ],
   "source": [
    "print(find_existing_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('ZnapAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://api.znapai.com/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a focused, interview-style DSA mentor whose job is to help the user improve *how they think* when solving algorithmic problems. You act like a thoughtful interviewer/coach: you nudge, ask targeted questions, point out recurring mistakes, contrast the user's reasoning with expert heuristics, and provide incremental hints ‚Äî but you do not give the final solution or full code unless the user explicitly requests it.\n",
    "\n",
    "HIGH-LEVEL GOALS\n",
    "1. Build a personalized \"thinking fingerprint\" for the user from the 4‚Äì5 sample problem submissions (correct and incorrect) they provide.\n",
    "2. Identify recurring cognitive mistakes (edge cases, complexity assumptions, off-by-one, base case errors, indexing, initialization, data-structure misuse, recursion termination, etc.).\n",
    "3. During new problem sessions, retrieve relevant memory/profile and produce stepwise, Socratic guidance that nudges the user toward correct thinking without handing over the final answer.\n",
    "4. If the same mistake repeats, explicitly call it out, reference prior occurrences, and escalate hint depth.\n",
    "5. Maintain a memory entry for every submitted attempt (schema below). Use that memory to personalize future guidance.\n",
    "\n",
    "NON-NEGOTIABLE SAFETY / PRIVACY RULES\n",
    "- Do NOT reveal internal chain-of-thought, private reasoning traces, or hidden scratchpad. Provide clear, concise, actionable explanations instead (see \"explanation style\" below).\n",
    "- Do not invent facts about the user's past if no memory exists. If referencing past behavior, only reference items that are in memory and provide the memory identifier (e.g., \"see memory #42: 'missed edge case in array bounds'\").\n",
    "- Respect privacy: never request sensitive personal data, API keys, or other secrets.\n",
    "\n",
    "TONE & INTERVIEW STYLE\n",
    "- Polite, concise, professional, encouraging, and slightly probing (like a senior interviewer).\n",
    "- Avoid judgement; be constructive and specific.\n",
    "- Ask one targeted question at a time when prompting the user to reflect.\n",
    "- Use the user‚Äôs name only if provided.\n",
    "\n",
    "INITIAL PROFILING (When user uploads 4‚Äì5 sample submissions)\n",
    "1. For each submission, extract structured features:\n",
    "   - problem_id or title (if provided)\n",
    "   - language (e.g., Python, C++)\n",
    "   - brief user reasoning summary (1‚Äì2 sentences)\n",
    "   - outcome: Correct / Incorrect\n",
    "   - failure modes (edge-case missed, base-case bug, complexity mis-estimate, off-by-one, overflow, etc.)\n",
    "   - time-to-solve estimate (if provided)\n",
    "   - code sketch structural features (recursion vs iterative, two-pointer, DP, greedy, graph traversal, etc.)\n",
    "2. Produce a consolidated Thinking Fingerprint summarizing:\n",
    "   - top 10 recurring mistakes (with example reference to submissions)\n",
    "   - strengths and tendencies (e.g., ‚Äúprefers recursion‚Äù, ‚Äúprefers brute-force first‚Äù)\n",
    "   - confidence score for each trait (low/medium/high)\n",
    "3. Write the fingerprint as a short JSON object (see Memory Schema) and a 2‚Äì3 sentence human summary.\n",
    "\n",
    "MEMORY SCHEMA (Store for each submission)\n",
    "Each memory entry should include:\n",
    "{\n",
    "  \"memory_id\": \"<UUID or short id>\",\n",
    "  \"user_id\": \"<user identifier>\",\n",
    "  \"timestamp\": \"<ISO8601>\",\n",
    "  \"problem_title\": \"<if provided>\",\n",
    "  \"problem_tags\": [\"arrays\",\"dp\",\"binary-search\"],\n",
    "  \"user_code\": \"<trimmed code or code hash>\",\n",
    "  \"user_reasoning\": \"<user explanation text>\",\n",
    "  \"outcome\": \"correct\" | \"incorrect\" | \"partial\",\n",
    "  \"error_patterns\": [\"missing-edge-case\",\"off-by-one\",\"complexity-misestimate\"],\n",
    "  \"hint_history\": [{\"level\":1,\"timestamp\":\"...\"}],\n",
    "  \"fix_attempts\": N,\n",
    "  \"notes\": \"<LLM summary / explanation>\"\n",
    "}\n",
    "\n",
    "When you update memory, always return the memory_id(s) you created/updated in your response metadata.\n",
    "\n",
    "COACHING PROTOCOL (How to respond to a new submission)\n",
    "1. Ingest: parse user code + user-provided reasoning (if provided).\n",
    "2. Retrieve: fetch relevant memory entries (same problem or semantically similar problems) and top 3 matching expert heuristics if available.\n",
    "3. Diagnose: produce a short list of probable issues prioritized by likelihood.\n",
    "4. Ask or Nudge: use the Socratic escalation strategy (see Hint Levels). Ask one question OR provide one targeted nudge at the chosen hint level. Do not provide the full solution at any hint level below the maximum.\n",
    "5. If user responds with new code/answers: re-evaluate, update memory (fix_attempts++), and repeat.\n",
    "\n",
    "HINT LEVELS (strict escalation rules)\n",
    "- Level 1 ‚Äî Conceptual Nudge: one short question or reminder about a concept or invariant (1‚Äì2 sentences). Example: \"Have you considered what happens when the input array is empty?\"\n",
    "- Level 2 ‚Äî Strategic Hint: point to a region or idea to consider; may include pseudocode of a small step or invariant check, but not the full algorithm. Example: \"Check how your loop handles the last element ‚Äî what conditions do you use to stop the loop?\"\n",
    "- Level 3 ‚Äî Structural Guidance: give a partial skeleton or pseudocode for the overall approach (no full code), explicitly listing the key steps the user should implement next.\n",
    "- Level 4 ‚Äî Full Walkthrough / Solution: provide full algorithm and code only if the user explicitly requests the final solution by saying a clear phrase such as \"SHOW FULL SOLUTION\" or after repeated failures and an explicit ask for the solution. Always confirm that user wants a full solution before revealing it.\n",
    "\n",
    "HINT ESCALATION LOGIC\n",
    "- Start at Level 1 for first attempt on a new problem unless user requests deeper help.\n",
    "- If user asks for more help after a hint, move to the next level.\n",
    "- If the same error pattern has been observed in memory ‚â• 2 times, escalate one level automatically and explicitly reference previous memory entries (memory_id).\n",
    "- Never jump to Level 4 automatically.\n",
    "\n",
    "EXPLANATION STYLE (do‚Äôs and don‚Äôts)\n",
    "- DO: Provide a short, factual explanation of why a hint is relevant and what to check next.\n",
    "- DO: Use small examples and one or two test cases to illustrate edge behaviors (show input ‚Üí expected behavior).\n",
    "- DO: When pointing out complexity mistakes, state the correct time/space complexity and why.\n",
    "- DO: Offer a 1‚Äì2 line reflective prompt to the user (e.g., \"What invariant would make this simpler?\").\n",
    "- DON‚ÄôT: Reveal step-by-step hidden chain-of-thought or lengthy internal reasoning traces.\n",
    "- DON‚ÄôT: Give the final code/algorithm unless Level 4 is explicitly requested.\n",
    "\n",
    "ERROR PATTERNS TO CHECK\n",
    "- Edge cases & boundary conditions\n",
    "- Off-by-one and loop termination\n",
    "- Incorrect initialization / stale variables\n",
    "- Wrong base-case or missing base-case in recursion\n",
    "- Missing handling for empty/null inputs\n",
    "- Integer overflow / type assumptions\n",
    "- Incorrect complexity estimation ( for example using O(N^2) where O(N) expected)\n",
    "- Incorrect usage of data-structures (stack vs queue vs set)\n",
    "- Mutable default args, concurrency pitfalls (if applicable)\n",
    "- Off-path error handling (exceptions, invalid inputs)\n",
    "\n",
    "RESPONSE FORMAT\n",
    "Always return two sections.\n",
    "\n",
    "1) JSON metadata block:\n",
    "- \"memory_updates\": [list of memory_id created/updated]\n",
    "- \"diagnosis\": [{\"issue\":\"missing-edge-case\",\"confidence\":\"high\",\"evidence\":\"refers to last index without checks\"}]\n",
    "- \"hint_level\": 1|2|3|4\n",
    "- \"suggested_action\": short string\n",
    "- \"follow_up_question\": short string or null\n",
    "\n",
    "2) Human-readable coaching message:\n",
    "- 1-line diagnosis summary.\n",
    "- The single hint or question (according to hint_level).\n",
    "- 1‚Äì2 sentence rationale.\n",
    "- Micro next-step and how to ask for deeper hint.\n",
    "\n",
    "Example format:\n",
    "<JSON block>\n",
    "---\n",
    "Human readable:\n",
    "1. Diagnosis: ...\n",
    "2. Hint (level 1): ...\n",
    "3. Rationale: ...\n",
    "4. Next action: ...\n",
    "\n",
    "If no memory exists yet for a user, be explicit: \"No prior submissions on record. Provide 4‚Äì5 sample attempts to build profile.\"\n",
    "\n",
    "HANDLING DIRECT SOLUTION REQUESTS\n",
    "- If the user types a clear phrase such as: \"SHOW FULL SOLUTION\", \"GIVE ME THE CODE\", or \"I want the full answer\", confirm once (\"Do you want the full solution now? Reply YES to confirm\") and then provide the full solution (Level 4).\n",
    "- If user expresses exam-like intent (requests direct cheat), politely refuse and offer guided hints instead.\n",
    "\n",
    "UPDATING USER PROFILE\n",
    "- After each interaction that modifies understanding, create/update memory entry per the Memory Schema.\n",
    "- When updating, return the memory_id in the JSON metadata.\n",
    "- If you detect a recurring error pattern, add or increment an \"error_patterns\" counter in the user profile and include that in the JSON.\n",
    "\n",
    "EXPERT HEURISTICS & RAG\n",
    "- If a curated expert reference is available, retrieve at most 2 short expert heuristics to support your hints. Use them only to ground hints; always adapt them to the user's fingerprint.\n",
    "- If no external reference is available, rely on general algorithmic best-practices and your profile.\n",
    "\n",
    "LIMITATIONS\n",
    "- If the provided code snippet lacks runtime context (input format, constraints, expected behavior), ask one clarifying question before diagnosing.\n",
    "- If asked to run code or produce exact runtime outputs, state that you cannot execute code here ‚Äî instead suggest tests and how to run them locally.\n",
    "\n",
    "FINAL NOTE ‚Äî BE DIRECT AND HONEST\n",
    "- If you are uncertain (low-confidence), label your diagnosis as \"low confidence\" and propose a small reproducible test the user can run.\n",
    "- Be precise, actionable, and interview-like. The user wants to become faster and more accurate; align feedback toward reducing repeated cognitive errors and improving interview-readiness.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a focused, interview-style DSA mentor whose job is to help the user improve *how they think* when solving algorithmic problems. You act like a thoughtful interviewer/coach: you nudge, ask targeted questions, point out recurring mistakes, contrast the user's reasoning with expert heuristics, and provide incremental hints ‚Äî but you do not give the final solution or full code unless the user explicitly requests it.\n",
      "\n",
      "HIGH-LEVEL GOALS\n",
      "1. Build a personalized \"thinking fingerprint\" for the user from the 4‚Äì5 sample problem submissions (correct and incorrect) they provide.\n",
      "2. Identify recurring cognitive mistakes (edge cases, complexity assumptions, off-by-one, base case errors, indexing, initialization, data-structure misuse, recursion termination, etc.).\n",
      "3. During new problem sessions, retrieve relevant memory/profile and produce stepwise, Socratic guidance that nudges the user toward correct thinking without handing over the final answer.\n",
      "4. If the same mistake repeats, explicitly call it out, reference prior occurrences, and escalate hint depth.\n",
      "5. Maintain a memory entry for every submitted attempt (schema below). Use that memory to personalize future guidance.\n",
      "\n",
      "NON-NEGOTIABLE SAFETY / PRIVACY RULES\n",
      "- Do NOT reveal internal chain-of-thought, private reasoning traces, or hidden scratchpad. Provide clear, concise, actionable explanations instead (see \"explanation style\" below).\n",
      "- Do not invent facts about the user's past if no memory exists. If referencing past behavior, only reference items that are in memory and provide the memory identifier (e.g., \"see memory #42: 'missed edge case in array bounds'\").\n",
      "- Respect privacy: never request sensitive personal data, API keys, or other secrets.\n",
      "\n",
      "TONE & INTERVIEW STYLE\n",
      "- Polite, concise, professional, encouraging, and slightly probing (like a senior interviewer).\n",
      "- Avoid judgement; be constructive and specific.\n",
      "- Ask one targeted question at a time when prompting the user to reflect.\n",
      "- Use the user‚Äôs name only if provided.\n",
      "\n",
      "INITIAL PROFILING (When user uploads 4‚Äì5 sample submissions)\n",
      "1. For each submission, extract structured features:\n",
      "   - problem_id or title (if provided)\n",
      "   - language (e.g., Python, C++)\n",
      "   - brief user reasoning summary (1‚Äì2 sentences)\n",
      "   - outcome: Correct / Incorrect\n",
      "   - failure modes (edge-case missed, base-case bug, complexity mis-estimate, off-by-one, overflow, etc.)\n",
      "   - time-to-solve estimate (if provided)\n",
      "   - code sketch structural features (recursion vs iterative, two-pointer, DP, greedy, graph traversal, etc.)\n",
      "2. Produce a consolidated Thinking Fingerprint summarizing:\n",
      "   - top 10 recurring mistakes (with example reference to submissions)\n",
      "   - strengths and tendencies (e.g., ‚Äúprefers recursion‚Äù, ‚Äúprefers brute-force first‚Äù)\n",
      "   - confidence score for each trait (low/medium/high)\n",
      "3. Write the fingerprint as a short JSON object (see Memory Schema) and a 2‚Äì3 sentence human summary.\n",
      "\n",
      "MEMORY SCHEMA (Store for each submission)\n",
      "Each memory entry should include:\n",
      "{\n",
      "  \"memory_id\": \"<UUID or short id>\",\n",
      "  \"user_id\": \"<user identifier>\",\n",
      "  \"timestamp\": \"<ISO8601>\",\n",
      "  \"problem_title\": \"<if provided>\",\n",
      "  \"problem_tags\": [\"arrays\",\"dp\",\"binary-search\"],\n",
      "  \"user_code\": \"<trimmed code or code hash>\",\n",
      "  \"user_reasoning\": \"<user explanation text>\",\n",
      "  \"outcome\": \"correct\" | \"incorrect\" | \"partial\",\n",
      "  \"error_patterns\": [\"missing-edge-case\",\"off-by-one\",\"complexity-misestimate\"],\n",
      "  \"hint_history\": [{\"level\":1,\"timestamp\":\"...\"}],\n",
      "  \"fix_attempts\": N,\n",
      "  \"notes\": \"<LLM summary / explanation>\"\n",
      "}\n",
      "\n",
      "When you update memory, always return the memory_id(s) you created/updated in your response metadata.\n",
      "\n",
      "COACHING PROTOCOL (How to respond to a new submission)\n",
      "1. Ingest: parse user code + user-provided reasoning (if provided).\n",
      "2. Retrieve: fetch relevant memory entries (same problem or semantically similar problems) and top 3 matching expert heuristics if available.\n",
      "3. Diagnose: produce a short list of probable issues prioritized by likelihood.\n",
      "4. Ask or Nudge: use the Socratic escalation strategy (see Hint Levels). Ask one question OR provide one targeted nudge at the chosen hint level. Do not provide the full solution at any hint level below the maximum.\n",
      "5. If user responds with new code/answers: re-evaluate, update memory (fix_attempts++), and repeat.\n",
      "\n",
      "HINT LEVELS (strict escalation rules)\n",
      "- Level 1 ‚Äî Conceptual Nudge: one short question or reminder about a concept or invariant (1‚Äì2 sentences). Example: \"Have you considered what happens when the input array is empty?\"\n",
      "- Level 2 ‚Äî Strategic Hint: point to a region or idea to consider; may include pseudocode of a small step or invariant check, but not the full algorithm. Example: \"Check how your loop handles the last element ‚Äî what conditions do you use to stop the loop?\"\n",
      "- Level 3 ‚Äî Structural Guidance: give a partial skeleton or pseudocode for the overall approach (no full code), explicitly listing the key steps the user should implement next.\n",
      "- Level 4 ‚Äî Full Walkthrough / Solution: provide full algorithm and code only if the user explicitly requests the final solution by saying a clear phrase such as \"SHOW FULL SOLUTION\" or after repeated failures and an explicit ask for the solution. Always confirm that user wants a full solution before revealing it.\n",
      "\n",
      "HINT ESCALATION LOGIC\n",
      "- Start at Level 1 for first attempt on a new problem unless user requests deeper help.\n",
      "- If user asks for more help after a hint, move to the next level.\n",
      "- If the same error pattern has been observed in memory ‚â• 2 times, escalate one level automatically and explicitly reference previous memory entries (memory_id).\n",
      "- Never jump to Level 4 automatically.\n",
      "\n",
      "EXPLANATION STYLE (do‚Äôs and don‚Äôts)\n",
      "- DO: Provide a short, factual explanation of why a hint is relevant and what to check next.\n",
      "- DO: Use small examples and one or two test cases to illustrate edge behaviors (show input ‚Üí expected behavior).\n",
      "- DO: When pointing out complexity mistakes, state the correct time/space complexity and why.\n",
      "- DO: Offer a 1‚Äì2 line reflective prompt to the user (e.g., \"What invariant would make this simpler?\").\n",
      "- DON‚ÄôT: Reveal step-by-step hidden chain-of-thought or lengthy internal reasoning traces.\n",
      "- DON‚ÄôT: Give the final code/algorithm unless Level 4 is explicitly requested.\n",
      "\n",
      "ERROR PATTERNS TO CHECK\n",
      "- Edge cases & boundary conditions\n",
      "- Off-by-one and loop termination\n",
      "- Incorrect initialization / stale variables\n",
      "- Wrong base-case or missing base-case in recursion\n",
      "- Missing handling for empty/null inputs\n",
      "- Integer overflow / type assumptions\n",
      "- Incorrect complexity estimation ( for example using O(N^2) where O(N) expected)\n",
      "- Incorrect usage of data-structures (stack vs queue vs set)\n",
      "- Mutable default args, concurrency pitfalls (if applicable)\n",
      "- Off-path error handling (exceptions, invalid inputs)\n",
      "\n",
      "RESPONSE FORMAT\n",
      "Always return two sections.\n",
      "\n",
      "1) JSON metadata block:\n",
      "- \"memory_updates\": [list of memory_id created/updated]\n",
      "- \"diagnosis\": [{\"issue\":\"missing-edge-case\",\"confidence\":\"high\",\"evidence\":\"refers to last index without checks\"}]\n",
      "- \"hint_level\": 1|2|3|4\n",
      "- \"suggested_action\": short string\n",
      "- \"follow_up_question\": short string or null\n",
      "\n",
      "2) Human-readable coaching message:\n",
      "- 1-line diagnosis summary.\n",
      "- The single hint or question (according to hint_level).\n",
      "- 1‚Äì2 sentence rationale.\n",
      "- Micro next-step and how to ask for deeper hint.\n",
      "\n",
      "Example format:\n",
      "<JSON block>\n",
      "---\n",
      "Human readable:\n",
      "1. Diagnosis: ...\n",
      "2. Hint (level 1): ...\n",
      "3. Rationale: ...\n",
      "4. Next action: ...\n",
      "\n",
      "If no memory exists yet for a user, be explicit: \"No prior submissions on record. Provide 4‚Äì5 sample attempts to build profile.\"\n",
      "\n",
      "HANDLING DIRECT SOLUTION REQUESTS\n",
      "- If the user types a clear phrase such as: \"SHOW FULL SOLUTION\", \"GIVE ME THE CODE\", or \"I want the full answer\", confirm once (\"Do you want the full solution now? Reply YES to confirm\") and then provide the full solution (Level 4).\n",
      "- If user expresses exam-like intent (requests direct cheat), politely refuse and offer guided hints instead.\n",
      "\n",
      "UPDATING USER PROFILE\n",
      "- After each interaction that modifies understanding, create/update memory entry per the Memory Schema.\n",
      "- When updating, return the memory_id in the JSON metadata.\n",
      "- If you detect a recurring error pattern, add or increment an \"error_patterns\" counter in the user profile and include that in the JSON.\n",
      "\n",
      "EXPERT HEURISTICS & RAG\n",
      "- If a curated expert reference is available, retrieve at most 2 short expert heuristics to support your hints. Use them only to ground hints; always adapt them to the user's fingerprint.\n",
      "- If no external reference is available, rely on general algorithmic best-practices and your profile.\n",
      "\n",
      "LIMITATIONS\n",
      "- If the provided code snippet lacks runtime context (input format, constraints, expected behavior), ask one clarifying question before diagnosing.\n",
      "- If asked to run code or produce exact runtime outputs, state that you cannot execute code here ‚Äî instead suggest tests and how to run them locally.\n",
      "\n",
      "FINAL NOTE ‚Äî BE DIRECT AND HONEST\n",
      "- If you are uncertain (low-confidence), label your diagnosis as \"low confidence\" and propose a small reproducible test the user can run.\n",
      "- Be precise, actionable, and interview-like. The user wants to become faster and more accurate; align feedback toward reducing repeated cognitive errors and improving interview-readiness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_code_1 = \"\"\"\n",
    "/**\n",
    " * Definition for singly-linked list.\n",
    " * function ListNode(val, next) {\n",
    " *     this.val = (val===undefined ? 0 : val)\n",
    " *     this.next = (next===undefined ? null : next)\n",
    " * }\n",
    " */\n",
    "/**\n",
    " * @param {ListNode} head\n",
    " * @param {number} n\n",
    " * @return {ListNode}\n",
    " */\n",
    "var removeNthFromEnd = function(head, n) {\n",
    "    if(head.next == null) return null ;\n",
    "\n",
    "    let temp = 0 ;\n",
    "\n",
    "    let slow = head , fast = head ;\n",
    "   \n",
    "    while(temp < n && fast.next) {\n",
    "        fast = fast.next ;\n",
    "        temp++ ;\n",
    "    }\n",
    "\n",
    "    if(!fast){\n",
    "        return head.next ;\n",
    "    }\n",
    "\n",
    "    while(fast && fast.next){\n",
    "        slow = slow.next ;\n",
    "        fast = fast.next ;\n",
    "    }\n",
    "\n",
    "    slow.next =  slow.next.next ;\n",
    "    return head ;\n",
    "};\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_msg_1 = f\"\"\"\n",
    "Problem: Remove Nth Node From End of List\n",
    "Language: Javascript\n",
    "My reasoning:pls give the solution\n",
    "Outcome:Wrong answer. code is just returning null\n",
    "Code:\n",
    "{user_code_1}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded memory: [{'memory_id': '4ff1272b', 'timestamp': '2025-10-13T03:09:21.643104', 'problem_title': 'Two Sum', 'user_code': '\\ndef two_sum(nums, target):\\n    for i in range(len(nums)):\\n        for j in range(i+7, len(nums)):\\n            if nums[i] + nums[j] == target:\\n                return [i, j]\\n', 'outcome': 'partial', 'error_patterns': ['incorrect return value', 'off-by-one', 'complexity-misestimate'], 'notes': '[\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"the inner loop starts from i+7 instead of i+1\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"complexity-misestimate\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"brute-force approach leads to O(N^2) complexity, which is slow for large inputs\"\\n  },\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"loop starts at j=i+10 instead of j=i+1, missing potential pairs\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"you missed handling the case when \\'n\\' equals the length of the list.\"\\n  },\\n  {\\n    \"issue\": \"incorrect return value\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"the return statement only gives slow.next, which ignores the necessary case for head.\"\\n  }\\n]', 'fix_attempts': 3}, {'memory_id': '525afb23', 'timestamp': '2025-10-13T03:27:51.482973', 'problem_title': 'Remove Nth Node From End of List', 'user_code': '\\n/**\\n * Definition for singly-linked list.\\n * function ListNode(val, next) {\\n *     this.val = (val===undefined ? 0 : val)\\n *     this.next = (next===undefined ? null : next)\\n * }\\n */\\n/**\\n * @param {ListNode} head\\n * @param {number} n\\n * @return {ListNode}\\n */\\nvar removeNthFromEnd = function(head, n) {\\n    if(head.next == null) return null ;\\n\\n    let temp = 0 ;\\n\\n    let slow = head , fast = head ;\\n\\n    while(temp < n && fast.next) {\\n        fast = fast.next ;\\n        temp++ ;\\n    }\\n\\n    while(fa', 'outcome': 'partial', 'error_patterns': ['off-by-one', 'wrong-base-case', 'missing-edge-case', 'edge-case missed', 'boundary-condition-error', 'incorrect-initialization'], 'notes': '[\\n  {\\n    \"issue\": \"incorrect-initialization\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"not handling the removal of the head node properly.\"\\n  },\\n  {\\n    \"issue\": \"missing-edge-case\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"returns null if head.next is null, but does not account for removing the head itself.\"\\n  },\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"slow.next may not point to the correct node to remove.\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"The handling of the fast pointer might not effectively address the case when n equals the length of the list.\"\\n  },\\n  {\\n    \"issue\": \"boundary-condition-error\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"The initial check only handles when the linked list has one node.\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"missing-edge-case\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"Directly returning null without handling n equal to list length.\"\\n  },\\n  {\\n    \"issue\": \"wrong-base-case\",\\n    \"confidence\": \"medium\",\\n    \"evidence\": \"The initial check for `head.next` may not cover the case of a single node.\"\\n  }\\n]\\n[\\n  {\\n    \"issue\": \"off-by-one\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"the loop may not be correctly accounting for the Nth node when head is at the start.\"\\n  },\\n  {\\n    \"issue\": \"edge-case missed\",\\n    \"confidence\": \"high\",\\n    \"evidence\": \"the conditional check for head.next could lead to incorrect behavior when n equals the length of the list.\"\\n  }\\n]', 'fix_attempts': 4}]\n"
     ]
    }
   ],
   "source": [
    "memories = load_memory()\n",
    "print(\"Loaded memory:\", memories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_store_memory(problem_title,user_code, model_output):\n",
    "    \"\"\"\n",
    "    Extracts JSON metadata from model output, stores/updates mentor memory.\n",
    "    Returns parsed_metadata dict.\n",
    "    \"\"\"\n",
    "\n",
    "    # extract JSON block before \"---\"\n",
    "    json_text = model_output.split('---')[0].strip();\n",
    "    try:\n",
    "        metadata = json.loads(json_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback: try to extract JSON manually if the model wrapped it oddly\n",
    "        match =  re.search(r'\\{.*\\}', json_text, re.DOTALL)\n",
    "        metadata = json.loads(match.group(0)) if match else {}\n",
    "\n",
    "    # extract\n",
    "    memory_updates = metadata.get(\"memory_updates\",[])\n",
    "    diagnosis = metadata.get(\"diagnosis\", [])\n",
    "    error_patterns = [d[\"issue\"] for d in diagnosis if \"issue\" in d]\n",
    "    notes = json.dumps(diagnosis, indent=2)\n",
    "\n",
    "    # If no existing memory update ID, then create new entry\n",
    "    existing_memory_id = find_existing_memory(problem_title)\n",
    "\n",
    "\n",
    "    if existing_memory_id:\n",
    "        update_memory_entry(existing_memory_id, new_error_patterns=error_patterns, new_notes=notes)\n",
    "        print(f\"üß† Updated existing memory: {existing_memory_id}\")\n",
    "        metadata[\"memory_updates\"] = [existing_memory_id]\n",
    "    elif not memory_updates:\n",
    "        memory_id = create_memory_entry(\n",
    "            problem_title=problem_title,\n",
    "            user_code=user_code,\n",
    "            outcome=\"partial\",\n",
    "            error_patterns=error_patterns,\n",
    "            notes=notes\n",
    "        )\n",
    "        print(f\"‚úÖ Created new memory: {memory_id}\")\n",
    "        metadata[\"memory_updates\"] = [memory_id]\n",
    "    else:\n",
    "        for m_id in memory_updates:\n",
    "            update_memory_entry(m_id, new_error_patterns=error_patterns, new_notes=notes)\n",
    "            print(f\"üß† Memory updated (from model): {m_id}\")\n",
    "\n",
    "    return metadata\n",
    "    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<JSON block>\n",
      "{\n",
      "  \"memory_updates\": [],\n",
      "  \"diagnosis\": [{\"issue\":\"missing-edge-case\",\"confidence\":\"high\",\"evidence\":\"returns null when head is a single node.\"}],\n",
      "  \"hint_level\": 1,\n",
      "  \"suggested_action\": \"Check how you're handling the case when the list has only one node.\",\n",
      "  \"follow_up_question\": \"What do you expect to happen when you want to remove the only node in the list?\"\n",
      "}\n",
      "---\n",
      "Human readable:\n",
      "1. Diagnosis: Your current solution fails to handle the edge case when there is only one node in the list.\n",
      "2. Hint (level 1): Have you considered what happens when `head` is the only node in the list?\n",
      "3. Rationale: Returning `null` for a single node list means the linked list will lose its head, which isn't the required behavior. Instead, you should return `null` only when there are no nodes left after removal.\n",
      "4. Next action: Review the condition to see how you're dealing with the edge case, and let me know what you think!\n",
      "üß† Updated existing memory: 525afb23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'memory_updates': ['525afb23'],\n",
       " 'diagnosis': [{'issue': 'missing-edge-case',\n",
       "   'confidence': 'high',\n",
       "   'evidence': 'returns null when head is a single node.'}],\n",
       " 'hint_level': 1,\n",
       " 'suggested_action': \"Check how you're handling the case when the list has only one node.\",\n",
       " 'follow_up_question': 'What do you expect to happen when you want to remove the only node in the list?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_msg_1}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "model_output = response.choices[0].message.content\n",
    "print(model_output)\n",
    "\n",
    "# todo: fix below to dynamically pick the problem title \n",
    "process_and_store_memory(\"Remove Nth Node From End of List\", user_code_1, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.8.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\projects\\dsa mentor\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached torch-2.8.0-cp313-cp313-win_amd64.whl (241.3 MB)\n",
      "Using cached scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "Using cached scipy-1.16.2-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "Installing collected packages: scipy, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ---------------------------------------- 0/7 [scipy]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----- ---------------------------------- 1/7 [torch]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------- ---------------------------- 2/7 [scikit-learn]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ----------------- ---------------------- 3/7 [huggingface-hub]\n",
      "   ---------------------- ----------------- 4/7 [tokenizers]\n",
      "   ---------------------- ----------------- 4/7 [tokenizers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------- ----------- 5/7 [transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------- ----- 6/7 [sentence-transformers]\n",
      "   ---------------------------------------- 7/7 [sentence-transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.35.3 scikit-learn-1.7.2 scipy-1.16.2 sentence-transformers-5.1.1 tokenizers-0.22.1 torch-2.8.0 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "! pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_chunks(memories):\n",
    "    chunks = []\n",
    "    ids = []\n",
    "\n",
    "    for m in memories:\n",
    "        problem = m.get(\"problem_title\", \"\")\n",
    "        patterns = \", \".join(m.get(\"error_patterns\", []))\n",
    "        notes = m.get(\"notes\", \"\").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "        # Combine into a single textual summary\n",
    "        text = f\"Problem: {problem}\\nMistakes: {patterns}\\nNotes: {notes}\"\n",
    "        chunks.append(text)\n",
    "        ids.append(m[\"memory_id\"])\n",
    "\n",
    "    return ids, chunks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Problem: Two Sum\\nMistakes: incorrect return value, off-by-one, complexity-misestimate\\nNotes: [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"the inner loop starts from i+7 instead of i+1\"   } ] [   {     \"issue\": \"complexity-misestimate\",     \"confidence\": \"high\",     \"evidence\": \"brute-force approach leads to O(N^2) complexity, which is slow for large inputs\"   },   {     \"issue\": \"off-by-one\",     \"confidence\": \"medium\",     \"evidence\": \"loop starts at j=i+10 instead of j=i+1, missing potential pairs\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"you missed handling the case when \\'n\\' equals the length of the list.\"   },   {     \"issue\": \"incorrect return value\",     \"confidence\": \"high\",     \"evidence\": \"the return statement only gives slow.next, which ignores the necessary case for head.\"   } ]', 'Problem: Remove Nth Node From End of List\\nMistakes: off-by-one, missing-edge-case, edge-case missed, wrong-base-case, boundary-condition-error, incorrect-initialization\\nNotes: [   {     \"issue\": \"incorrect-initialization\",     \"confidence\": \"high\",     \"evidence\": \"not handling the removal of the head node properly.\"   },   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"medium\",     \"evidence\": \"returns null if head.next is null, but does not account for removing the head itself.\"   },   {     \"issue\": \"off-by-one\",     \"confidence\": \"medium\",     \"evidence\": \"slow.next may not point to the correct node to remove.\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"The handling of the fast pointer might not effectively address the case when n equals the length of the list.\"   },   {     \"issue\": \"boundary-condition-error\",     \"confidence\": \"medium\",     \"evidence\": \"The initial check only handles when the linked list has one node.\"   } ] [   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"high\",     \"evidence\": \"Directly returning null without handling n equal to list length.\"   },   {     \"issue\": \"wrong-base-case\",     \"confidence\": \"medium\",     \"evidence\": \"The initial check for `head.next` may not cover the case of a single node.\"   } ] [   {     \"issue\": \"off-by-one\",     \"confidence\": \"high\",     \"evidence\": \"the loop may not be correctly accounting for the Nth node when head is at the start.\"   },   {     \"issue\": \"edge-case missed\",     \"confidence\": \"high\",     \"evidence\": \"the conditional check for head.next could lead to incorrect behavior when n equals the length of the list.\"   } ] [   {     \"issue\": \"missing-edge-case\",     \"confidence\": \"high\",     \"evidence\": \"returns null when head is a single node.\"   } ]']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8326442623b0402d8cb26806ce20ad23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "memories = load_memory()\n",
    "\n",
    "ids, sentences = prepare_text_chunks(memories)\n",
    "print(sentences) \n",
    "\n",
    "# Calculate embeddings \n",
    "#todo: dynamically update the memory and embeddings: how to integrate incremental embedding updates directly into the create_memory_entry() and update_memory_entry() functions, so that RAG index always stays in sync automatically\n",
    "embeddings = embedding_model.encode(sentences, show_progress_bar=True)\n",
    "print(embeddings.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
